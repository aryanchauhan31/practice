import time
from vllm import LLM, SamplingParams


llm = LLM(
    model="meta-llama/Llama-3.1-8B-Instruct",
    dtype="bfloat16",          
    max_model_len=8192,
    gpu_memory_utilization=0.8,
    enforce_eager=True
)

# Create a batch of prompts (Simulate 20 users)
prompts = [
    "Write a short poem about the speed of light.",
    "Explain quantum entanglement in simple terms.",
    "What is the capital of France and why is it famous?",
    "Write a Python function to merge two sorted lists.",
] * 5  

sampling_params = SamplingParams(temperature=0.8, max_tokens=256)

# Warmup (Compile graphs)
print("Warming up...")
llm.generate(prompts[:2], sampling_params)

# Run Benchmark
print(f"Benchmarking with {len(prompts)} prompts...")
start = time.time()
outputs = llm.generate(prompts, sampling_params)
end = time.time()

# Calculate Throughput
total_tokens = sum(len(o.outputs[0].token_ids) for o in outputs)
duration = end - start
throughput = total_tokens / duration


print(f"Total Tokens Generated: {total_tokens}")
print(f"Time Taken: {duration:.2f}s")
print(f"Decoding Throughput: {throughput:.2f} tokens/s")



// Adding requests: 100%
//  20/20 [00:00<00:00, 1155.01it/s]
// Processed prompts: 100%
//  20/20 [00:05<00:00,  5.10s/it, est. speed input: 44.94 toks/s, output: 1000.34 toks/s]

// Total Tokens Generated: 5120
// Time Taken: 5.14s
// Decoding Throughput: 996.61 tokens/s
